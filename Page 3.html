<!DOCTYPE html>
<html>
<head>
<title>Artificial Intelligence  </title>
</head>
<body>
<h1> Artificial Intelligence  </h1>

	<h2>links</h2>
	<ul>
 <li><a href="index.html">main page</a></li>
 <li><a href="Page 1.html">Applications  of AI</a></li>
  <li><a href="Page 2.html">Advantages and DisAdvantages of artificial intelligence Table</a></li>
  <li><a href="Page 3.html">How can artificial intelligence be dangerous?</a></li>
   <li><a href="Page 4.html">Artificial Intelligence in the future </a></li>
</ul>



<b><h3><u><p style="color:DarkCyan">How can artificial intelligence be dangerous?</p></u></h3></b>
While we haven’t achieved super-intelligent machines yet, the legal, political, societal, financial and regulatory issues are so complex and wide-reaching that it’s necessary to take a look at them now so we are prepared to safely operate among them when the time comes. Outside of preparing for a future with super-intelligent machines now, artificial intelligence can already pose dangers in its current form. Let’s take a look at some key AI-related risks.

<ol>
<b><li>Autonomous weapons</li></b>
AI programmed to do something dangerous, as is the case with autonomous weapons programmed to kill, is one way AI can pose risks. It might even be plausible to expect that the nuclear arms race will be replaced with a global autonomous weapons race. Russia’s president Vladimir Putin said: “Artificial intelligence is the future, not only for Russia, but for all humankind. It comes with enormous opportunities, but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the ruler of the world.”
Aside from being concerned that autonomous weapons might gain a “mind of their own,” a more imminent concern is the dangers autonomous weapons might have with an individual or government that doesn’t value human life. Once deployed, they will likely be difficult to dismantle or combat.
<b><li>Social manipulation</li></b>
Social media through its autonomous-powered algorithms is very effective at target marketing. They know who we are, what we like and are incredibly good at surmising what we think. Investigations are still underway to determine the fault of Cambridge Analytica and others associated with the firm who used the data from 50 million Facebook users to try to sway the outcome of the 2016 U.S. presidential election and the U.K.'s Brexit referendum, but if the accusations are correct, it illustrates AI's power for social manipulation. By spreading propaganda to individuals identified through algorithms and personal data, AI can target them and spread whatever information they like, in whatever format they will find most convincing—fact or fiction.
<b><li>Invasion of privacy and social grading</li></b>
It is now possible to track and analyze an individual's every move online as well as when they are going about their daily business. Cameras are nearly everywhere, and facial recognition algorithms know who you are. In fact, this is the type of information that is going to power China's social credit system that is expected to give every one of its 1.4 billion citizens a personal score based on how they behave—things such as do they jaywalk, do they smoke in non-smoking areas and how much time they spend playing video games. When Big Brother is watching you and then making decisions based on that intel, it’s not only an invasion of privacy it can quickly turn to social oppression.
<b><li>Misalignment between our goals and the machine’s</li></b>
Part of what humans value in AI-powered machines is their efficiency and effectiveness. But, if we aren’t clear with the goals we set for AI machines, it could be dangerous if a machine isn’t armed with the same goals we have. For example, a command to “Get me to the airport as quickly as possible” might have dire consequences. Without specifying that the rules of the road must be respected because we value human life, a machine could quite effectively accomplish its goal of getting you to the airport as quickly as possible and do literally what you asked, but leave behind a trail of accidents.
<b><li>Discrimination</li></b>
Since machines can collect, track and analyze so much about you, it’s very possible for those machines to use that information against you. It’s not hard to imagine an insurance company telling you you’re not insurable based on the number of times you were caught on camera talking on your phone. An employer might withhold a job offer based on your “social credit score.”
Any powerful technology can be misused. Today, artificial intelligence is used for many good causes including to help us make better medical diagnoses, find new ways to cure cancer and make our cars safer. Unfortunately, as our AI capabilities expand we will also see it being used for dangerous or malicious purposes. Since AI technology is advancing so rapidly, it is vital for us to start to debate the best ways for AI to develop positively while minimizing its destructive potential.
</ol>
</body>
</html>